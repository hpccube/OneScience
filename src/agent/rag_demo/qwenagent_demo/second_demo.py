import json5
from qwen_agent.agents import Assistant
from qwen_agent.tools.base import BaseTool, register_tool
from qwen_agent.utils.output_beautify import typewriter_print


# Step 1 (Optional): Add a custom tool named `my_image_gen`.
@register_tool("Custom_op")
class Custom_op(BaseTool):
    description = "This function calculate the custom_op of two numbers, and return the final float result."
    # The `parameters` tell the agent what input parameters the tool has.
    parameters = [
        {
            "name": "a",
            "type": "float",
            "description": "the first number to calculate, float number",
            "required": True,
        },
        {
            "name": "b",
            "type": "float",
            "description": "the second number to calculate, float number",
            "required": True,
        },
    ]

    def call(self, params: str, **kwargs) -> float:
        # `params` are the arguments generated by the LLM agent.
        a = json5.loads(params)["a"]
        b = json5.loads(params)["b"]
        return json5.dumps({"op_result": a**2 - b**2}, ensure_ascii=False)


@register_tool("Custom_op_2")
class Custom_op_2(BaseTool):
    description = "This function calculate the custom_op of two numbers, and return the final float result."
    # The `parameters` tell the agent what input parameters the tool has.
    parameters = [
        {
            "name": "a",
            "type": "float",
            "description": "the first number to calculate, float number",
            "required": True,
        },
        {
            "name": "b",
            "type": "float",
            "description": "the second number to calculate, float number",
            "required": True,
        },
        {
            "name": "c",
            "type": "float",
            "description": "the third number to calculate, float number",
            "required": True,
        },
    ]

    def call(self, params: str, **kwargs) -> float:
        # `params` are the arguments generated by the LLM agent.
        a = json5.loads(params)["a"]
        b = json5.loads(params)["b"]
        c = json5.loads(params)["c"]
        return json5.dumps({"op_result": a**3 + b**3 + c**3}, ensure_ascii=False)


# Step 2: Configure the LLM you are using.
llm_cfg = {
    # Use a model service compatible with the OpenAI API, such as vLLM or Ollama:
    "model": "qwen7B",
    # base_url, also known as api_base
    "model_server": "http://localhost:8000/v1",
    "api_key": "EMPTY",
    # (Optional) LLM hyperparameters for generation:
    "generate_cfg": {"top_p": 0.8},
}

# Step 3: Create an agent. Here we use the `Assistant` agent as an example, which is capable of using tools and reading files.
system_instruction = """After receiving the user's request, you should:
- first find the numbers in the user's request,
- If get two numbers mthen call the Custom_op function to calculate the result,
- If get three numbers mthen call the Custom_op_3 function to calculate the result,
- If the result is positive, write a python script to calculate the square root of the result
- If the result is nagetive, write a python script to calculate the absluate value of the result
Please print the final answer to the users"""
tools = [
    "Custom_op",
    "Custom_op_2",
    "code_interpreter",
]  # `code_interpreter` is a built-in tool for executing code.
# files = ['./doc.pdf']  # Give the bot a PDF file to read.
bot = Assistant(
    llm=llm_cfg,
    system_message=system_instruction,
    function_list=tools,
)

# Step 4: Run the agent as a chatbot.
messages = []  # This stores the chat history.
while True:
    # For example, enter the query "draw a dog and rotate it 90 degrees".
    query = input("\nuser query: ")
    # Append the user query to the chat history.
    messages.append({"role": "user", "content": query})
    response = []
    response_plain_text = ""
    print("bot response:")
    for response in bot.run(messages=messages):
        # Streaming output.
        response_plain_text = typewriter_print(
            response, response_plain_text)
    # Append the bot responses to the chat history.
    messages.extend(response)
