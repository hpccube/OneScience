{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这个notebook中，我们展示了使用PINNsFormer方法求解ns方程的示例。\n",
    "\n",
    "在训练结束后，可视化了pinnsformer方法求解和精确解的误差。\n",
    "\n",
    "这个notebook中的代码本质是navier_stokes目录中代码的梳理，如果需要更细致的对比研究，请在四个对应的目录中运行相关的notebook文件。\n",
    "\n",
    "详细的项目介绍请参考REAEDME.md文件。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.模型介绍\n",
    "PINNsFormer是一种基于transformer的物理信息神经网络(PINN)，PINN结合了物理信息与神经网络，可以用于求解非线性偏微分方程(PDEs)。然而，传统的基于多层感知器（MLP）的PINNs忽视了实际物理系统中固有的重要时间依赖性，因此无法全局传播初始条件约束，并在不同场景下准确捕捉真实解。PINNsFormer通过利用多头注意力机制来捕捉时间依赖性，从而能够更准确地近似PDE解。PINNsFormer将点式输入转换为伪序列，并用序列损失取代点式PINNs损失。\n",
    "\n",
    "#### 2.环境安装\n",
    "本项目环境基于Python 3.10，DTK 24.04，PyTorch 2.0, OneScience, json, pickle, getopt等依赖库。\n",
    "在超算互联网平台上，我们提供了预先配置好的镜像，创建容器后即可获得已经设置好的运行环境，实现一键运行。\n",
    "如果onescience更新，需要手动安装onescience， onescience的包位于deepcfd工程文件中。\n",
    "可以使用以下指令手动更新安装onescience。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#请在python环境中检查，如果环境没有更新onescience，取消注释下一行代码并执行安装onescience\n",
    "!pip install onescience-0.1.1-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.环境依赖检查\n",
    "环境检测包含pytorch版本和dcu环境检测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "version = torch.__version__\n",
    "num = float(version[:3])\n",
    "assert num >= 2.0, \"Pytorch version must >= 2.0\"\n",
    "\n",
    "assert torch.cuda.is_available(), \"Pytorch need DCU\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.素材准备\n",
    "本例的数据位于navier_stokes目录下./navier_stokes/cylinder_nektar_wake.mat。这是一组圆柱绕流的仿真数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.训练模型\n",
    "这部分代码包括模型定义，数据集定义和训练过程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from torch.optim import LBFGS, Adam\n",
    "from tqdm import tqdm\n",
    "import scipy.io\n",
    "import sys\n",
    "import os\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "from onescience.utils.pinnsformer_util import *\n",
    "\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "data = scipy.io.loadmat('./navier_stokes/cylinder_nektar_wake.mat')\n",
    "\n",
    "U_star = data['U_star'] # N x 2 x T\n",
    "P_star = data['p_star'] # N x T\n",
    "t_star = data['t'] # T x 1\n",
    "X_star = data['X_star'] # N x 2\n",
    "\n",
    "N = X_star.shape[0]\n",
    "T = t_star.shape[0]\n",
    "\n",
    "# Rearrange Data \n",
    "XX = np.tile(X_star[:,0:1], (1,T)) # N x T\n",
    "YY = np.tile(X_star[:,1:2], (1,T)) # N x T\n",
    "TT = np.tile(t_star, (1,N)).T # N x T\n",
    "\n",
    "UU = U_star[:,0,:] # N x T\n",
    "VV = U_star[:,1,:] # N x T\n",
    "PP = P_star # N x T\n",
    "\n",
    "x = XX.flatten()[:,None] # NT x 1\n",
    "y = YY.flatten()[:,None] # NT x 1\n",
    "t = TT.flatten()[:,None] # NT x 1\n",
    "\n",
    "u = UU.flatten()[:,None] # NT x 1\n",
    "v = VV.flatten()[:,None] # NT x 1\n",
    "p = PP.flatten()[:,None] # NT x 1\n",
    "\n",
    "idx = np.random.choice(N*T,2500, replace=False)\n",
    "x_train = x[idx,:]\n",
    "y_train = y[idx,:]\n",
    "t_train = t[idx,:]\n",
    "u_train = u[idx,:]\n",
    "v_train = v[idx,:]\n",
    "\n",
    "x_train = np.expand_dims(np.tile(x_train[:], (5)) ,-1)\n",
    "y_train = np.expand_dims(np.tile(y_train[:], (5)) ,-1)\n",
    "t_train = make_time_sequence(t_train, num_step=5, step=1e-2)\n",
    "\n",
    "x_train = torch.tensor(x_train, dtype=torch.float32, requires_grad=True).to(device)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32, requires_grad=True).to(device)\n",
    "t_train = torch.tensor(t_train, dtype=torch.float32, requires_grad=True).to(device)\n",
    "u_train = torch.tensor(u_train, dtype=torch.float32, requires_grad=True).to(device)\n",
    "v_train = torch.tensor(v_train, dtype=torch.float32, requires_grad=True).to(device)\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, x, y, t, u, v):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.t = t\n",
    "        self.u = u\n",
    "        self.v = v\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx], self.t[idx], self.u[idx], self.v[idx]\n",
    "        \n",
    "dataset = MyDataset(x_train, y_train, t_train, u_train, v_train)\n",
    "batch_size = 128  \n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "class WaveAct(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(WaveAct, self).__init__() \n",
    "        self.w1 = nn.Parameter(torch.ones(1), requires_grad=True)\n",
    "        self.w2 = nn.Parameter(torch.ones(1), requires_grad=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w1 * torch.sin(x) + self.w2 * torch.cos(x)\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff=256):\n",
    "        super(FeedForward, self).__init__() \n",
    "        self.linear = nn.Sequential(*[\n",
    "            nn.Linear(d_model, d_ff),\n",
    "            WaveAct(),\n",
    "            nn.Linear(d_ff, d_ff),\n",
    "            WaveAct(),\n",
    "            nn.Linear(d_ff, d_model)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, heads):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.attn = nn.MultiheadAttention(embed_dim=d_model, num_heads=heads, batch_first=True)\n",
    "        self.ff = FeedForward(d_model)\n",
    "        self.act1 = WaveAct()\n",
    "        self.act2 = WaveAct()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x2 = self.act1(x)\n",
    "        x = x + self.attn(x2,x2,x2)[0]\n",
    "        x2 = self.act2(x)\n",
    "        x = x + self.ff(x2)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, heads):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.attn = nn.MultiheadAttention(embed_dim=d_model, num_heads=heads, batch_first=True)\n",
    "        self.ff = FeedForward(d_model)\n",
    "        self.act1 = WaveAct()\n",
    "        self.act2 = WaveAct()\n",
    "\n",
    "    def forward(self, x, e_outputs): \n",
    "        x2 = self.act1(x)\n",
    "        x = x + self.attn(x2, e_outputs, e_outputs)[0]\n",
    "        x2 = self.act2(x)\n",
    "        x = x + self.ff(x2)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, d_model, N, heads):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.N = N\n",
    "        self.layers = get_clones(EncoderLayer(d_model, heads), N)\n",
    "        self.act = WaveAct()\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(self.N):\n",
    "            x = self.layers[i](x)\n",
    "        return self.act(x)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, d_model, N, heads):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.N = N\n",
    "        self.layers = get_clones(DecoderLayer(d_model, heads), N)\n",
    "        self.act = WaveAct()\n",
    "        \n",
    "    def forward(self, x, e_outputs):\n",
    "        for i in range(self.N):\n",
    "            x = self.layers[i](x, e_outputs)\n",
    "        return self.act(x)\n",
    "\n",
    "\n",
    "\n",
    "class PINNsformer(nn.Module):\n",
    "    def __init__(self, d_out, d_model, d_hidden, N, heads):\n",
    "        super(PINNsformer, self).__init__()\n",
    "\n",
    "        self.linear_emb = nn.Linear(3, d_model)\n",
    "\n",
    "        self.encoder = Encoder(d_model, N, heads)\n",
    "        self.decoder = Decoder(d_model, N, heads)\n",
    "        self.linear_out = nn.Sequential(*[\n",
    "            nn.Linear(d_model, d_hidden),\n",
    "            WaveAct(),\n",
    "            nn.Linear(d_hidden, d_hidden),\n",
    "            WaveAct(),\n",
    "            nn.Linear(d_hidden, d_out)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x, y, t):\n",
    "        src = torch.cat((x,y,t), dim=-1)\n",
    "        src = self.linear_emb(src)\n",
    "        e_outputs = self.encoder(src)\n",
    "        d_output = self.decoder(src, e_outputs)\n",
    "        output = self.linear_out(d_output)\n",
    "        return output\n",
    "    \n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "\n",
    "model = PINNsformer(d_out=2, d_hidden=512, d_model=32, N=1, heads=2).to(device)\n",
    "model.apply(init_weights)\n",
    "optim = LBFGS(model.parameters(), lr=0.01, line_search_fn='strong_wolfe')\n",
    "\n",
    "n_params = get_n_params(model)\n",
    "\n",
    "print(model)\n",
    "print(\"totol param numbers:\",get_n_params(model))\n",
    "\n",
    "loss_track = []\n",
    "\n",
    "for epoch in range(10):  # 假设训练 10 个 epoch\n",
    "    for batch in tqdm(dataloader):\n",
    "        x_batch, y_batch, t_batch, u_batch, v_batch = batch\n",
    "        \n",
    "        def closure():\n",
    "            psi_and_p = model(x_batch, y_batch, t_batch)\n",
    "            psi = psi_and_p[:,:,0:1]\n",
    "            p = psi_and_p[:,:,1:2]\n",
    "\n",
    "            u = torch.autograd.grad(psi, y_batch, grad_outputs=torch.ones_like(psi), retain_graph=True, create_graph=True)[0]\n",
    "            v = - torch.autograd.grad(psi, x_batch, grad_outputs=torch.ones_like(psi), retain_graph=True, create_graph=True)[0]\n",
    "\n",
    "            u_t = torch.autograd.grad(u, t_batch, grad_outputs=torch.ones_like(u), retain_graph=True, create_graph=True)[0]\n",
    "            u_x = torch.autograd.grad(u, x_batch, grad_outputs=torch.ones_like(u), retain_graph=True, create_graph=True)[0]\n",
    "            u_y = torch.autograd.grad(u, y_batch, grad_outputs=torch.ones_like(u), retain_graph=True, create_graph=True)[0]\n",
    "            u_xx = torch.autograd.grad(u, x_batch, grad_outputs=torch.ones_like(u_x), retain_graph=True, create_graph=True)[0]\n",
    "            u_yy = torch.autograd.grad(u, y_batch, grad_outputs=torch.ones_like(u_y), retain_graph=True, create_graph=True)[0]\n",
    "\n",
    "            v_t = torch.autograd.grad(v, t_batch, grad_outputs=torch.ones_like(v), retain_graph=True, create_graph=True)[0]\n",
    "            v_x = torch.autograd.grad(v, x_batch, grad_outputs=torch.ones_like(v), retain_graph=True, create_graph=True)[0]\n",
    "            v_y = torch.autograd.grad(v, y_batch, grad_outputs=torch.ones_like(v), retain_graph=True, create_graph=True)[0]\n",
    "            v_xx = torch.autograd.grad(v, x_batch, grad_outputs=torch.ones_like(v_x), retain_graph=True, create_graph=True)[0]\n",
    "            v_yy = torch.autograd.grad(v, y_batch, grad_outputs=torch.ones_like(v_y), retain_graph=True, create_graph=True)[0]\n",
    "\n",
    "            p_x = torch.autograd.grad(p, x_batch, grad_outputs=torch.ones_like(p), retain_graph=True, create_graph=True)[0]\n",
    "            p_y = torch.autograd.grad(p, y_batch, grad_outputs=torch.ones_like(p), retain_graph=True, create_graph=True)[0]\n",
    "\n",
    "            f_u = u_t + (u * u_x + v * u_y) + p_x - 0.01 * (u_xx + u_yy) \n",
    "            f_v = v_t + (u * v_x + v * v_y) + p_y - 0.01 * (v_xx + v_yy)\n",
    "\n",
    "            loss = (\n",
    "                torch.mean((u[:, 0] - u_batch) ** 2) +\n",
    "                torch.mean((v[:, 0] - v_batch) ** 2) +\n",
    "                torch.mean(f_u ** 2) +\n",
    "                torch.mean(f_v ** 2)\n",
    "            )\n",
    "\n",
    "            loss_track.append(loss.item())\n",
    "\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            return loss\n",
    "\n",
    "        optim.step(closure)\n",
    " \n",
    "save_flag = False\n",
    "if save_flag:        \n",
    "    np.save('./ns_loss_pinnsformer.npy', loss_track)\n",
    "    torch.save(model.state_dict(), './ns_pinnsformer.pt')\n",
    "\n",
    "print(\"loss after train:\",loss_track[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.测试\n",
    "对训练好的模型进行评估。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snap = np.array([100])\n",
    "x_star = X_star[:,0:1]\n",
    "y_star = X_star[:,1:2]\n",
    "t_star = TT[:,snap]\n",
    "\n",
    "u_star = U_star[:,0,snap]\n",
    "v_star = U_star[:,1,snap]\n",
    "p_star = P_star[:,snap]\n",
    "\n",
    "x_star = np.expand_dims(np.tile(x_star[:], (5)) ,-1)\n",
    "y_star = np.expand_dims(np.tile(y_star[:], (5)) ,-1)\n",
    "t_star = make_time_sequence(t_star, num_step=5, step=1e-2)\n",
    "\n",
    "x_star = torch.tensor(x_star, dtype=torch.float32, requires_grad=True).to(device)\n",
    "y_star = torch.tensor(y_star, dtype=torch.float32, requires_grad=True).to(device)\n",
    "t_star = torch.tensor(t_star, dtype=torch.float32, requires_grad=True).to(device)\n",
    "\n",
    "psi_and_p = model(x_star, y_star, t_star)\n",
    "psi = psi_and_p[:,:,0:1]\n",
    "p_pred = psi_and_p[:,:,1:2]\n",
    "\n",
    "u_pred = torch.autograd.grad(psi, x_star, grad_outputs=torch.ones_like(psi), retain_graph=True, create_graph=True)[0]\n",
    "v_pred = - torch.autograd.grad(psi, y_star, grad_outputs=torch.ones_like(psi), retain_graph=True, create_graph=True)[0]\n",
    "\n",
    "u_pred = u_pred.cpu().detach().numpy()[:,0]\n",
    "v_pred = v_pred.cpu().detach().numpy()[:,0]\n",
    "p_pred = p_pred.cpu().detach().numpy()[:,0]\n",
    "\n",
    "\n",
    "error_u = np.linalg.norm(u_star-u_pred,2)/np.linalg.norm(u_star,2)\n",
    "error_v = np.linalg.norm(v_star-v_pred,2)/np.linalg.norm(v_star,2)\n",
    "error_p = np.linalg.norm(p_star-p_pred,2)/np.linalg.norm(p_star,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.可视化\n",
    "模型求解值（推理结果）和理论求解值（标签）以及两者误差的可视化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,3))\n",
    "plt.imshow((p_star).reshape(50,100), extent=[-3,8,-2,2], aspect='auto')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Exact p(x,t)')\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "if save_flag:\n",
    "    plt.savefig('./ns_exact.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,3))\n",
    "plt.imshow((p_pred).reshape(50,100), extent=[-3,8,-2,2], aspect='auto')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Predicted p(x,t)')\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "if save_flag:\n",
    "    plt.savefig('./ns_pinnsformer_pred.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,3))\n",
    "plt.imshow(np.abs(p_pred-p_star).reshape(50,100), extent=[-3,8,-2,2], aspect='auto')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Absolute Error')\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "if save_flag:\n",
    "    plt.savefig('./ns_pinnsformer_error.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
