# FNO

## Config file

The `config` directory contains many `yaml` config files with naming format `config_{1/2/3}D_{PDE name}.yaml` where all args for training and testing are saved. The explanations of some FNO specific args are as follows:

* training args:
    * `training_type`: string, set 'autoregressive' for autoregressive trainging using autoregressive loss or 'single' for single step training using single step loss.
    * `initial_step`: int, the number of input time steps. (default: 10)

* model args:
    * `num_channels`: int, the number of input channels and output channels that equals to the number of variables to be solved. For example, there are 3 variables to be solved for 1D Compressible NS equation: density, pressure and velocity.
    * `modes`: int, number of Fourier modes to multiply.
    * `width`: int, number of channels for the Fourier layer.

Training hyperparameters we used are as follows:

| PDE Name                    | spatial resolution / downsample rate | temporal resolution / downsample rate | lr    | epochs | batch size | weight decay | initial step | width | modes |
| :-------------------------- | :---------------------- | :----------------------- | :---- | :----- | :--------- | :----------- | :----------- | :---------- | :---------- |
| 1D Advection                | 1024/4                  | 201/5                    | 1.e-3 | 500    | 64         | 1.e-4        | 10           | 20          | 12          |
| 1D Diffusion-Reaction       | 1024/4                  | 101/1                    | 1.e-3 | 500    | 64         | 1.e-4        | 10           | 20          | 12          |
| 1D Burgers                  | 1024/4                  | 201/5                    | 1.e-3 | 500    | 64         | 1.e-4        | 10           | 20          | 12          |
| 1D Diffusion-Sorption       | 1024/4                  | 101/1                    | 1.e-3 | 500    | 64         | 1.e-4        | 10           | 20          | 12          |
| 1D Allen Cahn               | 1024/4                  | 101/1                    | 1.e-3 | 500    | 64         | 1.e-4        | 10           | 20          | 12          |
| 1D Cahn Hilliard            | 1024/4                  | 101/1                    | 1.e-3 | 500    | 64         | 1.e-4        | 10           | 20          | 12          |
| 1D Compressible NS          | 1024/4                  | 101/1                    | 1.e-3 | 500    | 64         | 1.e-4        | 10           | 20          | 12          |
| 2D Burgers                  | 128/1                   | 101/1                    | 1.e-3 | 500    | 8          | 1.e-4        | 10           | 20          | 12          |
| 2D Compressible NS          | 128/2                   | 21/1                     | 1.e-3 | 500    | 32         | 1.e-4        | 10           | 20          | 12          |
| 2D DarcyFlow                | 128/1                   | -                        | 1.e-3 | 500    | 64         | 1.e-4        | 1            | 20           | 12          |
| 2D Shallow Water            | 128/1                   | 101/1                    | 1.e-3 | 500    | 8          | 1.e-4        | 10           | 20          | 12          |
| 2D Allen Cahn               | 128/1                   | 101/1                    | 1.e-3 | 500    | 8          | 1.e-4        | 10           | 20          | 12          |
| 2D Black-Scholes-Barenblatt | 128/1                   | 101/1                    | 1.e-3 | 500    | 8          | 1.e-4        | 10           | 20          | 12          |
| 3D Compressible NS          | 128/2                   | 21/1                     | 1.e-3 | 500    | 2          | 1.e-4        | 10           | 20          | 12          |
| 3D Eular                    | 128/2                   | 21/1                     | 1.e-3 | 500    | 2          | 1.e-4        | 10           | 20          | 12          |
| 3D Maxwell                  | 32                      | 8                        | 1.e-3 | 500    | 2          | 1.e-4        | 2            | 20           | 12          |

## Loss function

FNO solves PDEs in autoregressive manner where model $f_{\theta}$ predicts the solution of next time steps $\hat{u}^{k+1}$ based on the solution of previous $l$ (`initial_step`) time steps $\{\hat{u}^{k-l+
1},...,\hat{u}^k\}$. The process can be formalized as

$$
\hat{u}^{k+1} = f_{\theta}(\hat{u}^{k-l+1},...,\hat{u}^k).
$$

The loss function has the form:

$$
\mathcal{L}=\frac{1}{N}\sum_{k=0}^{N-1}l(f_{\theta}(\hat{u}^{k-l+1},...,\hat{u}^k), u^{k+1})
$$ 

where $u^{k+1}$ is ground truth data generated by high-order numerical methods and $l$ is MSE in our implementation.

In practice, the soltuions of first $l$ time steps denoted as $\{u^0,...,u^{l-1}\}$ may be generated by other high-order methods, which are the initial model input. The solutions of remaining time steps are generated by trained model autoregressivly. And the input of remaining time steps will consists of model prediction.

## Training strategy

**Single step training**: The input to model always comes from ground truth data. So that the loss function has the form:

$$
\mathcal{L}=\frac{1}{N}\sum_{k=0}^{N-1}l(f_{\theta}(u^{k-l+1},...,u^k), u^{k+1}).
$$

**Autoregressive training**: Standard training strategy. In addition to the initial input comes from ground truth data, the intermediate inputs comes from model prediction. The loss function has the same form as above.

## Train

1. Check the following args in the config file:
    1. The path of `file_name` and `saved_folder` are correct;
    2. `if_training` is `True`;
2. Set hyperparameters for training, such as `lr`, `batch size`, etc. You can use the default values we provide;
3. Run command:
```bash
CUDA_VISIBLE_DEVICES=0 python train.py ./config/train/${config file name}
# Example: CUDA_VISIBLE_DEVICES=0 python train.py ./config/train/config_1D_Advection.yaml
```

## Resume training

1. Modify config file:
    1. Make sure `if_training` is `True`;
    2. Set `continue_training` to `True`;
    3. Set `model_path` to the checkpoint path where traing restart;
2. Run command:
```bash
CUDA_VISIBLE_DEVICES=0 python train.py ./config/train/${config file name}
```

## Test

1. Modify config file:
    1. Set `if_training` to `False`;
    2. Set `model_path` to the checkpoint path where the model to be evaluated is saved.
2. Run command:
```bash
CUDA_VISIBLE_DEVICES=0 python train.py ./config/test/${config file name}
```